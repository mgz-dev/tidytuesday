---
title: "2022-05-10 NYT Best Sellers"
date: 2022-05-11
output: html_document
editor_options: 
  chunk_output_type: console
---

# TidyTuesday

Join the R4DS Online Learning Community in the weekly #TidyTuesday event!
Every week we post a raw dataset, a chart or article related to that dataset, and ask you to explore the data.
While the dataset will be “tamed”, it will not always be tidy! As such you might need to apply various R for Data Science techniques to wrangle the data into a true tidy format.
The goal of TidyTuesday is to apply your R skills, get feedback, explore other’s work, and connect with the greater #RStats community!
As such we encourage everyone of all skills to participate!

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidytuesdayR)

```

# Load the weekly Data

Download the weekly data and make available in the `tt` object.

```{r Load}

nyt_titles <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_titles.tsv')
nyt_full <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_full.tsv')


```



# Glimpse Data

Take an initial look at the format of the data available.

```{r Glimpse}

nyt_titles %>% glimpse()
nyt_full %>% glimpse()

```

# Wrangle
```{r}
nyt_titles %>% 
  group_by(author, title) %>% 
  summarize(n = n()) %>% 
  arrange(-n)

```
We see that the same book can appear in the NYT bestseller lists as multiple entries, but it is uncommon


```{r Wrangle}
library(stringr)

pattern = regex("\\W+")

nyt_analysis <- nyt_titles %>%
  mutate(clean_title = str_squish(str_replace_all(title, pattern = pattern, " ")),
         char_n_title = str_length(clean_title),
         words_n_title = lengths(str_split(clean_title, " "))
  )

nyt_analysis
```


# Visualize

Using your processed dataset, create your unique visualization.

```{r Visualize}

nyt_analysis %>%
  ggplot() + 
  geom_bar() + 
  aes(year) +
  ggtitle("Count of books entering NYT Bestsellers list by year") +
  theme_bw()


nyt_analysis %>%
  ggplot() + 
  geom_histogram() +
  aes(total_weeks) + 
  ggtitle("Distribution of length (wks) in NYT Bestsellers List") +
  theme_bw()
```

Which authors show up the most on the NYT Best Sellers list?

```{r}
nyt_grouped <- nyt_analysis %>%
  group_by(author) %>%
  summarize(n = n(),
            mean_weeks = mean(total_weeks),
            median_weeks = median(total_weeks)) %>%
  arrange(-n)

nyt_grouped
```


What words most frequently appear in NYT Best Seller titles?

```{r}
library(tidytext)

title_words <- nyt_analysis %>%
  select(clean_title, author, year,  total_weeks) %>%
  unnest_tokens(word, clean_title) %>%
  anti_join(stop_words, by = "word")

title_words %>%
  group_by(word) %>%
  summarize(n = n()) %>%
  slice_max(order_by = n, n = 50) %>%
  mutate(word = fct_reorder(word, n)) %>%
  ggplot() +
  geom_col() + 
  aes(x = n, y = word) + 
  ggtitle("Most common words in titles of NYT Bestsellers") + 
  theme_bw()
```

# Follow along with Julia Silge Analysis

## Build tidymodel


```{r setup-model}
library(tidymodels)

set.seed(1234)

nyt_split <- nyt_analysis %>%
  transmute(
    author,
    total_weeks = if_else(total_weeks > 4, "long", "short")) %>%
  na.omit() %>%
  initial_split(strat = total_weeks)

nyt_train <- training(nyt_split)
nyt_test <- testing(nyt_split)

set.seed(2345)
nyt_folds <- vfold_cv(nyt_train, strata = total_weeks)
nyt_folds


```


```{r setup-model2}
library(textrecipes)
svm_spec <- svm_linear(mode = "classification")

nyt_recipe <- recipe(total_weeks ~ author, data = nyt_train) %>%
  step_tokenize_wordpiece(author) %>%
  step_tokenfilter(author, max_tokens = 100) %>%
  step_tf(author) %>%
  step_normalize(all_numeric_predictors())

prep(nyt_recipe) %>% bake(new_data = NULL) %>% skimr::skim()


nyt_wf <- workflow(nyt_recipe, svm_spec)

nyt_wf
```

## Evaluate models
```{r}
set.seed(1234)

#doParallel::registerDoParallel()

nyt_metrics <- metric_set(accuracy, sens, spec)
nyt_rs <- fit_resamples(nyt_wf, resamples = nyt_folds, metrics = nyt_metrics)

collect_metrics(nyt_rs)

```

```{r}
final_rs <- last_fit(nyt_wf, nyt_split, metrics = nyt_metrics)
collect_metrics(final_rs)
```

```{r}
collect_predictions(final_rs) %>%
  conf_mat(total_weeks, .pred_class) %>%
  autoplot()
```

```{r}
final_fitted <- extract_workflow(final_rs)

#predict(final_fitted, new_data = slice_sample(nyt_test, n = 1))
augment(final_fitted, new_data = slice_sample(nyt_test, n = 1))

```


```{r}
tidy(final_fitted) %>%
  slice_max(abs(estimate), n = 20) %>%
  mutate(term = str_remove_all(term, "tf_author_"),
         term = fct_reorder(term, abs(estimate))
         ) %>%
  ggplot(aes(x = abs(estimate), y = term, fill = estimate > 0 )) + 
  geom_col() + 
  scale_fill_discrete(labels = c("Fewer weeks", "More weeks"))  +
  labs(y = NULL, fill = "Time on NYT Bestseller?", title = "NYT Bestseller Predictors")
```


# deployable model objects with Vetiver
```{r}
library(vetiver)

v <- vetiver_model(final_fitted, "nyt_authors")
v

#library(plumber)

#pr() %>%
#  vetiver_api(v) %>%
#  pr_run()
```


# Save Image

Save your image for sharing. Be sure to use the `#TidyTuesday` hashtag in your post on twitter! 

```{r}

# This will save your most recent plot
ggsave(
  filename = "My TidyTuesday Plot.png",
  device = "png")

```
